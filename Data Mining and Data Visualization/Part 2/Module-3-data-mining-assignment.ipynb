{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module-3-data-mining-exercise-notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Idor0b53AFHt","colab_type":"text"},"source":["This assignment will have you running two clustering algorithms and two dimensionality reduction algorithms and comparing the results. We will use synthetic data for simplicity. Follow along with the text in this notebook and add code to do that tasks when prompted. Start by importing the necessary libraries:"]},{"cell_type":"code","metadata":{"id":"c3GHE7s69Hhj","colab_type":"code","colab":{}},"source":["# these are the libraries you will need\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.datasets import make_blobs\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","\n","# fixes random seed to that results are reproducible\n","np.random.seed(1337)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMb8AxodBDft","colab_type":"text"},"source":["First we will test the two clustering algorithms. Refer to the notes and examples. You can take code from my examples and edit as needed or write on your own. Do not copy results from other places on the internet (although you can google for ideas - please cite sources in comments if you do that).\n","\n","You will be comparing k-means and dbscan. We need some data to do that. We will be using the make_blobs function from sklearn to generate clusters (http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)\n","This function randomly samples data from some normal distributions.\n","\n","Run the following code to generate data:\n"]},{"cell_type":"code","metadata":{"id":"U_G24G7G-QYy","colab_type":"code","colab":{}},"source":["# after running this, blobs contains the synthetic data (it is a 2-d array)\n","# and cluster_labels is a list that contains the ground truth cluster assignments\n","# for the clustering algorithm evaluation you shouldn't have to use \n","# cluster_labels as we want the algorithms to discover the algorithms on their own \n","centers = [[-7, -7], [-7, 9], [8, -1]]\n","blobs, cluster_labels = make_blobs(n_samples=1000, n_features=2, centers=centers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8Xbjj67vamf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"outputId":"b4e5e335-8614-4fd0-fbe5-72d268603743","executionInfo":{"status":"ok","timestamp":1570309570460,"user_tz":360,"elapsed":362,"user":{"displayName":"Nait DS","photoUrl":"","userId":"05692387954560017085"}}},"source":["pd.DataFrame(blobs, columns=['x', 'y'])"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-7.356896</td>\n","      <td>-6.992282</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-7.545606</td>\n","      <td>-4.278954</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.376102</td>\n","      <td>0.019389</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-6.368661</td>\n","      <td>9.216636</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-7.259445</td>\n","      <td>9.819258</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          x         y\n","0 -7.356896 -6.992282\n","1 -7.545606 -4.278954\n","2  8.376102  0.019389\n","3 -6.368661  9.216636\n","4 -7.259445  9.819258"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"xcZWKtw2CBY-","colab_type":"text"},"source":["# Task #1\n","\n","Run kmeans and dscan on the blobs data. For both algorithms, make a scatter plot that shows the blobs data with the colour of the scatter points corresponding to the clusters found by the algorithm. For each algorithm, record the run time of it. The title of each plot should have the following format:\n","\n","[algorithm name] Time: [algorithm runtime] \n","\n","You can record the runtime by using the time.process_time() function. Make sure your notebook runtime is set to Python3 (as this function doesn't exist in Python2). Grab the runtime of an algorithm by calling time.process_time() before and after the algorithm call and computing the difference in times. Time is recorded in seconds.\n","\n","You do not need to make legends or axis labels. If you want to go ahead, but we will not hold it against you if you don't (for time considerations).\n","\n","Note: for the kmeans algorithm, your choice of the n_init parameter will greatly affect runtime. I use 1000 as an arbitrary value. If you have some extra time, try adjusting the value and see how low you can make it while still getting useful results.  This is very clean, low-dimensional data so having a large number here is probably not that important.\n","\n","Marks (1 each):\n","\n","\n","\n","*   Run Kmeans\n","*   Run dbscan\n","*   Record run times correctly\n","*   Make plots\n","*   have clusters in plots shown by color\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"14IeHid98nCW","colab_type":"code","colab":{}},"source":["## code for running clustering algorithms and making plots goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caqL1m2NMCeq","colab_type":"text"},"source":["## Optional tasks\n","\n","If you have time after doing Task #1, the next step is to try these clustering algorithms on some of the datasets we have used already. Here are some possible candidates, in order of how much work preparing the dataset might be:\n","\n","*   Iris Dataset\n","*   Mushroom Dataset\n","*   Beer dataset\n","*   Agriculture dataset\n","\n","For different datasets, the analysis could be different.\n","\n","Iris:\n","\n","* Cluster without using the species label. Then colour by species label after clustering. Can you cluster to obtain the species groups without telling your algorithm explicitly about the what the clusters should be?\n","\n","Mushroom:\n","\n","* Similar to Iris, except now we are dealing with categories. Remove the poison or edible label before cluster. Cluster and then colour by poison or edible.\n","* You need to encode the categories in a way that lends itself to clustering. Think about dummy variables or ordinal encodings depending on the column. Dummy variables for everything is an okay choice for you first analysis.\n","* Can you categorize your clusters in interesting ways? What mushrooms are grouped together? In terms of the other columns, what do the clusters represent?\n","\n","Beer:\n","\n","* Remove the style label and then cluster by the numerical attributes. Now color by style. Can you seperate them? What styles don't separate numerically and which do?\n","\n","Agriculture:\n","\n","* Remove region and category. Cluster. Can you separate the data in a way that gives insight into the regions?\n","* Can you use the centroids of each cluster to give insight into the clusters?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O6hsDT3LEwv0","colab_type":"text"},"source":["# Task #2\n","\n","First, run the following code to generate the new data:"]},{"cell_type":"code","metadata":{"id":"X48V5cvUExBZ","colab_type":"code","colab":{}},"source":["# for dimensionality reduction we want higher dimenional data\n","# run this code to regenerate blobs in a higher dimension\n","# this lime, cluster_labels is actually useful since we want to see how\n","# the dimensionality reduction algorithms let us visualize the original clusters\n","blobs, cluster_labels = make_blobs(n_samples=1000, n_features=10, centers=3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iY2E_5GrFQq-","colab_type":"text"},"source":["Run pca and tsne on the higher dimension blobs data. For both algorithms, make a scatter plot that shows the blobs data with the colour of the scatter points corresponding to the original cluster labels. You can specify the pca and tsne algorithms to project the blob data onto 2 dimensions (n_components=2) and then plot the transformed data in 2 dimensions. For each algorithm, record the run time of it. The title of each plot should have the following format:\n","\n","[algorithm name] Time: [algorithm runtime]\n","\n","You can record the runtime by using the time.process_time() function. Make sure your notebook runtime is set to Python3 (as this function doesn't exist in Python2). Grab the runtime of an algorithm by calling time.process_time() before and after the algorithm call and computing the difference in times. Time is recorded in seconds.\n","\n","You do not need to make legends or axis labels. If you want to go ahead, but we will not hold it against you if you don't (for time considerations).\n","\n","If you have some extra time, try playing around with the algorithm parameters and see what happens!\n","\n","Marks (1 each):\n","\n","\n","*   Run PCA\n","*   Run TSNE\n","*   Plots are made correctly\n","\n","There are less marks for task 2 because we expect you to reuse plotting code from task 1. Try to think about an effective way to organize your code (Hint: functions rule!!).\n"]},{"cell_type":"code","metadata":{"id":"sTy8uWleFFkp","colab_type":"code","colab":{}},"source":["## code for running the dimensionality reduction algorithms goes here\n","# feel free to use your solution for making plots from task #1 (actually we \n","# encourage it - data scientists don't like doing the same thing twice!)\n"],"execution_count":0,"outputs":[]}]}