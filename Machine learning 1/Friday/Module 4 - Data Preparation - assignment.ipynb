{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module-4-Data-Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-P-ssnaqmb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic libraries you need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The following is code for uploading a file to the colab.research.google \n",
        "# environment.\n",
        "\n",
        "# library for uploading files\n",
        "from google.colab import files \n",
        "\n",
        "def upload_files():\n",
        "    # initiates the upload - follow the dialogues that appear\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # verify the upload\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    # uploaded files need to be written to file to interact with them\n",
        "    # as part of a file system\n",
        "    for filename in uploaded.keys():\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(uploaded[filename])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeGq2Gao8k5h",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "This assignment is about preparing data for machine learning experiments. We have given you a dataset called \"Melbourne_house_FULL.csv\". You can find out about this dataset here:\n",
        "\n",
        "https://www.kaggle.com/anthonypino/melbourne-housing-market\n",
        "\n",
        "The dataset is for a housing price prediction task. The price column is the target value and the rest of the columns are features. We will request a series of cleaning tasks from you. The final result should be a dataset ready to do ML with.\n",
        "\n",
        "Load the dataset using the code below. Notice that some columns are dropped. This is intentional as some of the columns in the original dataset are difficult to work with.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WK69lE9tzU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_files()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmU4Bx1GuZGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "house_df = pd.read_csv(\"Melbourne_housing_FULL.csv\")\n",
        "house_df = house_df.drop([\"Suburb\", \"Address\", \"Date\", \"Postcode\", \"SellerG\", \"CouncilArea\", \"Lattitude\", \"Longtitude\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ7jH-loub7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run EDA\n",
        "house_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d0AVAbKy_6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "house_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KybstcH19qdF",
        "colab_type": "text"
      },
      "source": [
        "### 1) Remove Null prices\n",
        "\n",
        "Remove any row where the Price column is null. Remember, if you are scared of messing with the data while testing ideas make a copy of it by calling `.copy` on the original dataframe. For the rest of the exercise, assume that operations should be done on the dataframe with no null Prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587FcZvT-GMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "house_df.Feature.notnull()\n",
        "house_df.Feature.isnull()\n",
        "house_df.loc[]\n",
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifc5UVZc-Iki",
        "colab_type": "text"
      },
      "source": [
        "### 2) Replace null \"Regionname\" values with the most frequent region name\n",
        "\n",
        "Don't use Imputer objects for this, as sklearn's Imputer objects are not equipped to handle categorical data.\n",
        "\n",
        "Hint: You can get the name of the most frequent value in a series by going `series_object.value_counts.index[0]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XrGn31-0c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn3zAmXj-8ov",
        "colab_type": "text"
      },
      "source": [
        "### 3) Impute the numerical columns with the mean value of that column\n",
        "\n",
        "Use the Imputer class with default arguments to do this. We started you off by listing the numerical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hC45fhZ_PWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "num_columns = [\"Landsize\",\n",
        "               \"Distance\",\n",
        "               \"BuildingArea\",\n",
        "               \"Propertycount\"]\n",
        "\n",
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGnVJsAD_XeZ",
        "colab_type": "text"
      },
      "source": [
        "### 4) Impute the integer columns with the most frequent value of that column\n",
        "\n",
        "Use the Imputer class with `strategy=most_frequent`. We started you off by listing the integer columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_pZAAeE_o6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "int_columns = [\"Bedroom2\",\n",
        "               \"Bathroom\",\n",
        "               \"Car\",\n",
        "               \"YearBuilt\"]\n",
        "\n",
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUYKKPBUADY-",
        "colab_type": "text"
      },
      "source": [
        "### 5) Discretize the BuildingArea Column by making a new column named BuildingAreaDiscrete\n",
        "\n",
        "More specifically, make a new column that has three new categories \"small\", \"medium\", \"large\". We listed the labels to use below.\n",
        "\n",
        "Use the pd.qcut function to do this. Note: You may have to use the argument `duplicates=\"drop\"` if you are getting an error.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrAhuywGAHr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "building_labels = [\"small\", \"medium\", \"large\"]\n",
        "new_column_name = \"BuildingAreaDiscrete\"\n",
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa0pMz3x_x_X",
        "colab_type": "text"
      },
      "source": [
        "### 6) Make dummy variables of the categorical columns\n",
        "\n",
        "We use pd.get_dummies to do this, but if you are comfortable with a different technique go ahead and try that. We identified that categorical columns we want \"dummified\" for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow0Jxs-jAA2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_columns = [\"Type\", \"Method\", \"Regionname\", \"BuildingAreaDiscrete\"]\n",
        "\n",
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7vmlne1Bypu",
        "colab_type": "text"
      },
      "source": [
        "### 7)  Remove the top 1% of Prices\n",
        "\n",
        "Remove rows that have a Price in the top 1% of prices. This corresponds prices above the 99th percentile. Use the `quantile` method to accomplish this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-d1X7PmBwv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31bXbzx1CL0I",
        "colab_type": "text"
      },
      "source": [
        "### 8) Engineer a new column called \"BathroomRatio\"\n",
        "\n",
        "Make a new column named \"BathroomRatio\". This column is the number of bathrooms divided by the number of rooms. This gives an idea of the number of bathrooms in proportion to the size of the house."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ac9qMgCPqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn_O0L25Cljs",
        "colab_type": "text"
      },
      "source": [
        "### 9) Separate the Price column from the other features\n",
        "\n",
        "Make two new variables:\n",
        "1) A Series that contains just the Price column\n",
        "2) A DataFrame that contains every other feature\n",
        "Use reasonable names for these two new variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePY37MTNDJ97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNySn8yDJa3",
        "colab_type": "text"
      },
      "source": [
        "### 10) Divide the data into a train and test set\n",
        "\n",
        "Use `train_test_split` from `sklearn.model_selection` to accomplish this. Use a test size of 10%. Use the variables you made in number **9)** to accomplish this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOkhMwSrDy05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE3tgvE9EBJV",
        "colab_type": "text"
      },
      "source": [
        "### 11) Scale the data\n",
        "\n",
        "Scale the features using standardization. You can use whatever technique for doing this.\n",
        "\n",
        "Bonus: Scale just using the training features and then transform (scale) the test features using the mean and stddev learned from the training features. This can be done most efficiently with the `StandardScaler` class in `sklearn.preprocessing`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7uOpcP-Crb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}