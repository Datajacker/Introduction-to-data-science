{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Module-4-Logistic-Regression-Assignment-Description.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"tL2kj4s5njq0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Libraries you will need\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_wine\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XXnMD1mcoFnt","colab_type":"code","colab":{}},"cell_type":"code","source":["# load the data and check out the description\n","wine = load_wine()\n","feat_df = pd.DataFrame(wine[\"data\"], columns=wine[\"feature_names\"])\n","target_series = pd.Series(wine[\"target\"])\n","print(wine[\"DESCR\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9QgzoGetoNh5","colab_type":"code","colab":{}},"cell_type":"code","source":["#EDA can go here"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dHTUoqxH_CPR","colab_type":"text"},"cell_type":"markdown","source":["### Task\n","\n","We want you to implement the one-vs-rest method for multiclass prediction. This is the main idea to that algorithm:\n","\n","\n","\n","*   For each class C:\n","       -         make a class vector that has 1 if the class is class C, 0 otherwise\n","       -         Train a classifier using that vector as the labels\n","*   When classifying on test set\n","       -      Make a prediction with each classifier\n","       -      Predicted class is max probability predicted by the classifiers\n","                                                                      \n","We have provided the main outline of the Cross Validation experiment. You need to fill in the contents of the two inner loops. There are comment in the code that direct you where to put your code and what steps you should take. You will need to use our predefined function (binarize_class) and the LogisticRegression class:\n","\n","http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"]},{"metadata":{"id":"lYEwLOw8pIht","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","def binarize_class(class_array, class_int):\n","    \"\"\"\n","    class_array - the original class vector(contains multiple class labels)\n","    class_int - int, the label of the class you want to transform to one-vs-rest\n","    \"\"\"\n","    return class_array.map(lambda x, y=class_int: 1 if x==y else 0)\n","\n","total_labels = []\n","total_preds = []\n","\n","np.random.seed(1340)\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","for train_indices, test_indices in skf.split(feat_df, target_series):\n","    x_train = feat_df.iloc[train_indices, :]\n","    y_train = target_series.iloc[train_indices]\n","    \n","    x_test = feat_df.iloc[test_indices, :]\n","    y_test = target_series.iloc[test_indices]\n","    \n","    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n","    x_train_scaled = scaler.fit_transform(x_train)\n","    \n","    regressors = []\n","    for y_class in y_train.unique():\n","        # fill in the code for training here\n","        # Use binarize_class to transform the y_train vector for each class\n","        # Use LogisticRegression() model and fit it to the binarized vector\n","        # store resulting model in the regressors list\n","\n","    preds = []\n","    for regressor in regressors:\n","        # fill in the code for predicting here\n","        # make a probability prediction on the x_test array with \n","        # each regressor (classifier) that you trained\n","        # turn the prediction into a single column (the output is usually two columns)\n","        # You can use [:, [1]] to do that transformation\n","        # store the prediction vector in the preds list\n","    \n","    # this is the actual argmax computation in numpy\n","    # after you have populated preds, these lines will select the class with\n","    # the highest probability prediction\n","    preds = np.concatenate(preds, axis=1)\n","    preds = np.argmax(preds, axis=1)\n","\n","    total_labels.extend(list(y_test))\n","    total_preds.extend(list(preds))\n","\n","acc = accuracy_score(total_labels, total_preds)\n","print(\"Score:\", acc)"],"execution_count":0,"outputs":[]}]}